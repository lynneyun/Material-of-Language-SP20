{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifesto in Color\n",
    "\n",
    "by [Lynne Yun](http://www.lynneyun.com)\n",
    "\n",
    "Let's try to convert manifesto text to a colorful piece of art!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following was adapted from Allison's 'Letters as Numbers' class demo.\n",
    "I decided to adapt the example where the text was getting converted to bytes, then to colors. \n",
    "\n",
    "Pillow, used above, uses 3 x 8 bit pixels in the 'RGB' mode within the '.frombytes' function, as shown here.\n",
    "https://pillow.readthedocs.io/en/latest/reference/Image.html#PIL.Image.frombytes\n",
    "\n",
    "In other words, Pillow takes in 3 bytes (each 8 bits) and shows the color. In other words, 'hello', which is expressed in 5 bytes as '104-101-108-108-111', is shown as ONE COLOR (and presumably the next letter would get mixed in with the next color). \n",
    "\n",
    "## Challenge: Have the bytes (per letter) correspond to one pixel each, and have the rest of the values be customizable.\n",
    "\n",
    "So for instance using the same example, I would like 'hello' to be expressed in 5 pixels. Now, I do realize that Pillow requires 3 bytes of information. My solution to this is that whatever info its missing just gets a predetermined number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are reviews of notes taken from Allison's demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Every glyph contains an encoded value that translates as numerals.\n",
    "#We can see this in this example of an 'a'\n",
    "\n",
    "ord(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also convert numerals to chars\n",
    "\n",
    "chr(126)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I wrote a short manifesto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I believe that all letterforms are powerful and powerless at the same time.\n",
      "I believe that all letterforms can be flexible in its form as long as the recipients agree on its format.\n",
      "I believe that no letterform is inherently good nor inherently bad.\n",
      "Letterforms are the foundations of communication but can also dismantle communication.\n",
      "The love for letterforms should be without boundaries.\n"
     ]
    }
   ],
   "source": [
    "#Let's print out the original text for us to read first.\n",
    "original_text = open(\"manifesto.txt\").read()\n",
    "print(original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a text file that contains the 'manifesto' document, and reading it as bytes\n",
    "\n",
    "text_bytes = open(\"manifesto.txt\", \"rb\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Pillow which enables the bytes to image conversion\n",
    "\n",
    "from PIL import Image, ImageOps, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pillow can only take bytes, not strings. so let's see what bytes make up manifesto\n",
    "# Sample taken from https://stackoverflow.com/questions/7585435/best-way-to-convert-string-to-bytes-in-python-3\n",
    "\n",
    "# for i in range(0,len(original_text)):\n",
    "#     print(bytes(original_text[i], 'utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the first attempt, a version where you can add glyphs as padding. (markdown so it's not enabled)\n",
    "\n",
    "### FYI, this failed because inputting glyphs has a limited value (up to 127), and RGB color range is 0~255\n",
    "\n",
    "\n",
    "green_default = '~'\n",
    "blue_default = ' '\n",
    "\n",
    "alt_text = ''\n",
    "for i in range(0,len(original_text)):\n",
    "    # Add original character to new string\n",
    "    alt_text += original_text[i]\n",
    "    \n",
    "    # Pad bytes with green and blue defaults\n",
    "    numbytes = len(bytes(original_text[i], 'utf8'))\n",
    "    if numbytes == 1:\n",
    "        alt_text += green_default + blue_default\n",
    "    elif numbytes == 2:\n",
    "        alt_text += blue_default\n",
    "    \n",
    "print(alt_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Version, where you can customize Green and Blue values\n",
    "\n",
    "For this, I recieved help from Kevin (Yeh)!\n",
    "\n",
    "Turns out I had my head mixed up in what bytes exactly where, and couldn't get the 'conversion' in my head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_default = (220).to_bytes(1, byteorder='big')\n",
    "blue_default = (200).to_bytes(1, byteorder='big')\n",
    "\n",
    "alt_text = bytearray()\n",
    "for i in range(0,len(original_text)):\n",
    "    # Add original character to new string\n",
    "    b = bytes(original_text[i], 'utf8')\n",
    "    alt_text += b\n",
    "    \n",
    "    # Pad bytes with green and blue defaults\n",
    "    numbytes = len(b)\n",
    "    if numbytes == 1:\n",
    "        alt_text += green_default\n",
    "        alt_text += blue_default\n",
    "    elif numbytes == 2:\n",
    "        alt_text += blue_default\n",
    "    \n",
    "## Uncomment to see what alt_text looks like\n",
    "## alt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted example from Allison.\n",
    "#note: the 'padded' bytes are there so no data gets cut off. \n",
    "#It looks like black areas because there was no data there, therefore defaulting to 0 light value. \n",
    "# The height is calulated from the width and drawn.\n",
    "\n",
    "width = 30\n",
    "padded_text_bytes = alt_text + (b' ' * width * 3)\n",
    "height = int ((len(padded_text_bytes)/3)/width)\n",
    "new_img = Image.frombytes('RGB', (width, height), bytes(padded_text_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAOCAIAAAC3hDtuAAACDElEQVR4nLXUvW4TURAF4G93/RPb2TjBb0HBK6AkGBIpJIikgAqJAomW56GlgSQSwVIQ5q9MQ50mooMCAcZeO/Ema5siXAkegKlmpDOjO+ecudH6ydExKyRUmVCwRI8uOwzJabHLMg3QYYOcJuiTMqRGwgUV4mOWWQwNVepE4C4DUhphbsqYDndIuEKfKVUyUkrsMyQiRotTfyJhEMp9FgKuzSee8gUBM6JERh3sEbEWRsX4QYkqyEPepM2UCTEp13nMMavMqNEhB8+J2KDPInP8JN6gRIcJm3QogRndf+l7xU+2eUeDiE3KdANXHZr8ouA90ZOTo4wpFarkFNSoMGOPZSo0yECXLWYcsE4jwG7+9YghLeK3POMrhwwoqHJBn4Q2H0g5pQh+mAWdE/pE7DAjYUjMEjnxgAdcBVVqFBSk9Kixw5glPpCxRcQoCFVnyi4lCuJggTHxJg1y7nMYXDzjcpvP9JnjgjYNzsACtynzkh53KThgnoSMLtGjk6NLZnNOmdBiFLgus8cWZ7xhlXmmYI6cC86Z/tt1wApxkzIvGDEhZZcxE8oUYETCNnUGRFQ544zDsMSlaytg/fJkvodinpSPfCOjYMBLNmiQMuAVZSKm4XTbLFFmTDmoWqNOfIVd6uRE3OIhi7xmQpsOc2Q0WQu+jMFp+BXOmdFjnnMyKkTXTo4GN+75D/EbKqu4xZk7PXkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=30x14 at 0x7FDB48353710>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing image\n",
    "new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAACMCAIAAABJdAN4AAAFX0lEQVR4nO3dza7dZQHF4W44IogFW0fchJcggUopSRMbNcEZM0bEATdlwkcHhYHaDhxWbqCTcwUEbCha+RIdyoRfY/6pa+DzTFd6zj5778V/wMr7nl47v3vh+92L7MKFlzN9MtMfZvrPTL/J9FKm9zO9nelvMv1bpl9m+tNM38v0pUyfzbR9mOn1TPvvff6/fi3/8VmmFzPtz+iZTPv7/HWmT2X6RKbAY6eEMKaEMKaEMKaEMKaEMKaEMKaEMKaEMHbWm5heY/wk088z7TXGjUx7f3DKtP0q0weZ9grkLNMjm5jeiDzM9E6mNzL9V6aXM/1rpv0X9daqv3XPZdrez7Q/o15EeRLCmBLCmBLCmBLCmBLCmBLCmBLCmBLCmBLCWA85HvF/+vvEjiP6PI/eW3x74PfezPTIGTP9Rr+S6V8yPc/0xUxbL4T6M+pTgvrd6NVLnyHUZ9v06qU/32sHfm/zJIQxJYQxJYQxJYQxJYQxJYQxJYQxJYQxJYSxRyxmPs20b/x5xI9OvT/on9xnkHTay5Xe4vRGpM/F6VNVevXSr7k3Ilcy7b+37zC6lemR+7zeyfRqpn2TVN/31Oux/re98fIkhDElhDElhDElhDElhDElhDElhDElhDElhLHTW+d3I+7lyu1MX8v0B5n23qJ/cu94+i6h3pf0GqMXJL0C+TrTDzLt+4D6dqT+e3tf0n9Rv8/9vfpjpo/v7z1yhlDvpbopnoQwpoQwpoQwpoQwpoQwpoQwpoQwpoQwpoQwdno7FzN9P06fQdKnqvRZL72o+CbTXq70qzqyp+klR//eXvn0p9B6q/HLTPvdsGr6rt7T9Pk0noQwpoQwpoQwpoQwpoQwpoQwpoQwpoQwpoQwdnYn4/NM+7age5keuZen1za9bPhHppcy7fuPepty5PySXgj1GqP1NuV04Cf3J9h3GD2fab+T/ZP7VfWn0Gub/ub0AsyTEMaUEMaUEMaUEMaUEMaUEMaUEMaUEMaUEMbOHmT8RqY/yrQXM7166Tubvsq078e5mOn9THsz0UuOLzLtvcXvM3010z5Fpv39wL/t/7r3N6fPLrqZaZ9t09ujfs0PM+3vVX/6noQwpoQwpoQwpoQwpoQwpoQwpoQwpoQwpoQwdvpd3srUdwn1DqA3BL0C6RNo+mSUPkfko0z7TJ1+VS9k2uemtD43pd/nI+emHLmlqL85R+636nVR32D1+M4B6p1W/15PQhhTQhhTQhhTQhhTQhhTQhhTQhhTQhhTQhg7vZmLmV5U9Cqib6LpEzt6f9D3EPXJKP2ae4vTJ9/0CqTPeum7ov6U6ZVMf5xpn+bSns60P/1e2/QZQv2aV9+NW5n21sqTEMaUEMaUEMaUEMaUEMaUEMaUEMaUEMaUEMbO+uyTXgm8m2kvOXr30OemvJdpn1DS56b0XVF9p0/rrUZvcX6dae9L+tatfp97QdIrn17M9Jkr/c157sDvPcv0yAKsb4Pqz8iTEMaUEMaUEMaUEMaUEMaUEMaUEMaUEMaUEMbOPsm4T+zolcCREzv+nOnHmfa9PL2JObLzuJ7pkaXO/Uz7VV3N9JRpr5o+zLTfjVcyXd1g1f+2z1vqtJc6noQwpoQwpoQwpoQwpoQwpoQwpoQwpoQwpoQwdnY54z7Npc8+6VNVeiPyaqY/z/SLTP+Qad+e0zuPXpC8nmmfBNMLkmuZ9vt8ZNXU+tatXq70jqdXTf2ae3t0KdM+U6fPH+pzcTwJYUwJYUwJYUwJYUwJYUwJYUwJYUwJYUwJYez0s/O7ET/4xW//Zy8F/j95EsKYEsKYEsKYEsKYEsKYEsKYEsKYEsKYEsLYvwF7RcBaRjjRrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=300x140 at 0x7FDB48353750>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#magnifying it \n",
    "show_scaled(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading it\n",
    "new_img.save(\"text_img.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
